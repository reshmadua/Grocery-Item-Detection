{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Grocery Item Detection and Bill Generation",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/reshmadua/Grocery-Item-detection/blob/main/Grocery%20item%20detection%20and%20bill%20generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mGmQbAO5pQb"
      },
      "source": [
        "# **Setup**\n",
        "\n",
        "**Clone repo, install dependencies and check PyTorch and GPU**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbvMlHd_QwMG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ab989dc-3567-4864-8792-b9209c27ec3d"
      },
      "source": [
        "!git clone https://github.com/ultralytics/yolov5  # clone repo\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt  # install dependencies\n",
        "\n",
        "import torch\n",
        "from IPython.display import Image, clear_output  # to display images\n",
        "\n",
        "clear_output()\n",
        "print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete. Using torch 1.9.0+cu102 (Tesla K80)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vi4TFurN2RY8"
      },
      "source": [
        "**Linking Google Drive in Google Colab notebook**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjSY2-2m2RY8",
        "outputId": "31c0685f-aca7-4cb1-f2e4-fa10714ffa1a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WoGIdVUh2RY8"
      },
      "source": [
        "**Copying Dataset from Google Drive to a folder in YOLOv5 directory**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5H6TiTh2RY9"
      },
      "source": [
        "%cp /content/gdrive/My\\ Drive/dataset.zip /content/dataset.zip"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pwr2SUcR2RY9"
      },
      "source": [
        "**Unzipping the Dataset zip file**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzvpvaQs2RY9"
      },
      "source": [
        "!unzip -q ../dataset.zip -d ../"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzbeLQ6I2mRz"
      },
      "source": [
        "# **Training**\n",
        "Training a YOLOv5s model on custom dataset with --data custom_data.yaml, starting from pretrained --weights yolov5s.pt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqm_91JX2tEE",
        "outputId": "c55f0641-0d90-425a-d100-2279d44c6aea"
      },
      "source": [
        "# !python train.py --img 640 --batch 16 --epochs 30 --data custom_data.yaml --weights yolov5s.pt --cache"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=custom_data.yaml, hyp=data/hyps/hyp.scratch.yaml, epochs=30, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, adam=False, sync_bn=False, workers=8, project=runs/train, entity=None, name=exp, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, upload_dataset=False, bbox_interval=-1, save_period=-1, artifact_alias=latest, local_rank=-1, freeze=0, patience=100\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 âœ…\n",
            "YOLOv5 ðŸš€ v5.0-431-gfcb225c torch 1.9.0+cu102 CUDA:0 (Tesla K80, 11441.1875MB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 ðŸš€ runs (RECOMMENDED)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v5.0/yolov5s.pt to yolov5s.pt...\n",
            "100% 14.1M/14.1M [00:00<00:00, 44.4MB/s]\n",
            "\n",
            "Overriding model.yaml nc=80 with nc=5\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
            "  9                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     26970  models.yolo.Detect                      [5, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "Model Summary: 283 layers, 7074330 parameters, 7074330 gradients, 16.4 GFLOPs\n",
            "\n",
            "Transferred 356/362 items from yolov5s.pt\n",
            "Scaled weight_decay = 0.0005\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 59 weight, 62 weight (no decay), 62 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mversion 1.0.3 required by YOLOv5, but version 0.1.12 is currently installed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '../dataset/labels/train' images and labels...340 found, 0 missing, 0 empty, 0 corrupted: 100% 340/340 [00:00<00:00, 1813.33it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: ../dataset/labels/train.cache\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.4GB ram): 100% 340/340 [00:03<00:00, 106.01it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '../dataset/labels/val' images and labels...60 found, 0 missing, 0 empty, 0 corrupted: 100% 60/60 [00:00<00:00, 528.90it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: ../dataset/labels/val.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.1GB ram): 100% 60/60 [00:01<00:00, 46.44it/s]\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "Plotting labels... \n",
            "\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 2.00, Best Possible Recall (BPR) = 1.0000\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/exp2\u001b[0m\n",
            "Starting training for 30 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      0/29     3.32G   0.08373   0.03006   0.03814        10       640: 100% 22/22 [00:25<00:00,  1.14s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:02<00:00,  1.26s/it]\n",
            "                 all         60         60     0.0172       0.05    0.00392   0.000856\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      1/29     3.78G   0.06805   0.02833    0.0363         9       640: 100% 22/22 [00:22<00:00,  1.00s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:01<00:00,  1.13it/s]\n",
            "                 all         60         60     0.0434     0.0667     0.0155    0.00454\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      2/29     3.78G   0.06275   0.02674   0.03824        11       640: 100% 22/22 [00:22<00:00,  1.01s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:01<00:00,  1.33it/s]\n",
            "                 all         60         60     0.0868      0.117     0.0677     0.0255\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      3/29     3.78G   0.04387   0.02627   0.03543         9       640: 100% 22/22 [00:22<00:00,  1.01s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:01<00:00,  1.39it/s]\n",
            "                 all         60         60      0.137      0.483      0.212     0.0683\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      4/29     3.78G   0.04153   0.02363   0.03376        12       640: 100% 22/22 [00:22<00:00,  1.01s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:01<00:00,  1.44it/s]\n",
            "                 all         60         60      0.565      0.278      0.301      0.147\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      5/29     3.78G   0.03532   0.02208   0.03249        10       640: 100% 22/22 [00:22<00:00,  1.01s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:01<00:00,  1.49it/s]\n",
            "                 all         60         60      0.269      0.466      0.327      0.099\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      6/29     3.78G   0.03733   0.01879   0.03459         8       640: 100% 22/22 [00:22<00:00,  1.01s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:01<00:00,  1.49it/s]\n",
            "                 all         60         60      0.452      0.383      0.356      0.201\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      7/29     3.78G   0.03839   0.01756     0.033        13       640: 100% 22/22 [00:22<00:00,  1.01s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:01<00:00,  1.50it/s]\n",
            "                 all         60         60      0.189      0.764      0.335        0.2\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      8/29     3.78G   0.03805   0.01511   0.03022        11       640: 100% 22/22 [00:21<00:00,  1.00it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:01<00:00,  1.52it/s]\n",
            "                 all         60         60      0.438      0.543      0.502      0.291\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      9/29     3.78G     0.031   0.01481   0.02952        11       640: 100% 22/22 [00:21<00:00,  1.00it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:01<00:00,  1.52it/s]\n",
            "                 all         60         60      0.515      0.647      0.616      0.361\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     10/29     3.78G   0.03364   0.01448   0.02736        11       640: 100% 22/22 [00:21<00:00,  1.00it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:01<00:00,  1.53it/s]\n",
            "                 all         60         60      0.442       0.65       0.54      0.337\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     11/29     3.78G   0.02869     0.014   0.02661        11       640: 100% 22/22 [00:21<00:00,  1.00it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:01<00:00,  1.54it/s]\n",
            "                 all         60         60      0.665      0.732      0.734      0.461\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     12/29     3.78G   0.02965   0.01387   0.02656        12       640: 100% 22/22 [00:21<00:00,  1.00it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:01<00:00,  1.52it/s]\n",
            "                 all         60         60       0.65      0.709      0.708      0.421\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     13/29     3.78G   0.02938   0.01309   0.02476        15       640: 100% 22/22 [00:21<00:00,  1.00it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:01<00:00,  1.51it/s]\n",
            "                 all         60         60      0.601      0.818      0.774      0.463\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     14/29     3.78G   0.02461   0.01263   0.02382         9       640: 100% 22/22 [00:22<00:00,  1.00s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:01<00:00,  1.54it/s]\n",
            "                 all         60         60      0.761       0.66      0.816      0.526\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     15/29     3.78G    0.0278   0.01273   0.02442        11       640: 100% 22/22 [00:22<00:00,  1.00s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:01<00:00,  1.52it/s]\n",
            "                 all         60         60      0.768      0.819      0.871      0.602\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     16/29     3.78G   0.03036   0.01235   0.02101        12       640: 100% 22/22 [00:22<00:00,  1.01s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:01<00:00,  1.52it/s]\n",
            "                 all         60         60      0.671      0.859      0.835      0.507\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     17/29     3.78G   0.02497   0.01189   0.02066        10       640: 100% 22/22 [00:22<00:00,  1.01s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:01<00:00,  1.53it/s]\n",
            "                 all         60         60      0.885        0.8      0.919      0.572\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     18/29     3.78G   0.02345   0.01133   0.01854        11       640: 100% 22/22 [00:22<00:00,  1.00s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:01<00:00,  1.51it/s]\n",
            "                 all         60         60      0.781      0.851      0.899      0.633\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     19/29     3.78G   0.02679   0.01095   0.01973        12       640: 100% 22/22 [00:22<00:00,  1.01s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:01<00:00,  1.52it/s]\n",
            "                 all         60         60      0.826      0.859      0.912      0.547\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     20/29     3.78G   0.02277   0.01143    0.0157        10       640: 100% 22/22 [00:22<00:00,  1.01s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:01<00:00,  1.53it/s]\n",
            "                 all         60         60      0.706      0.916      0.865      0.602\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     21/29     3.78G   0.02475   0.01096   0.01816        10       640: 100% 22/22 [00:22<00:00,  1.00s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:01<00:00,  1.53it/s]\n",
            "                 all         60         60      0.741      0.916      0.901      0.538\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     22/29     3.78G   0.02333   0.01093   0.01554         8       640: 100% 22/22 [00:22<00:00,  1.01s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:01<00:00,  1.54it/s]\n",
            "                 all         60         60      0.823       0.84      0.891      0.383\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     23/29     3.78G   0.03058   0.01092   0.01991        11       640: 100% 22/22 [00:22<00:00,  1.01s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:01<00:00,  1.55it/s]\n",
            "                 all         60         60      0.888      0.898      0.944      0.634\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     24/29     3.78G    0.0284   0.01146   0.01528        16       640: 100% 22/22 [00:22<00:00,  1.01s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:01<00:00,  1.54it/s]\n",
            "                 all         60         60      0.929      0.912      0.946      0.648\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     25/29     3.78G    0.0246   0.01101   0.01267        10       640: 100% 22/22 [00:22<00:00,  1.01s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:01<00:00,  1.54it/s]\n",
            "                 all         60         60      0.919      0.916      0.967      0.601\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     26/29     3.78G   0.02447   0.01053     0.013        11       640: 100% 22/22 [00:22<00:00,  1.00s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:01<00:00,  1.52it/s]\n",
            "                 all         60         60      0.854      0.887      0.941      0.693\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     27/29     3.78G   0.02196   0.01049   0.01196        12       640: 100% 22/22 [00:21<00:00,  1.00it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:01<00:00,  1.53it/s]\n",
            "                 all         60         60      0.835      0.817      0.888      0.596\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     28/29     3.78G   0.02033   0.01005   0.01278         8       640: 100% 22/22 [00:21<00:00,  1.00it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:01<00:00,  1.53it/s]\n",
            "                 all         60         60      0.825      0.949      0.948      0.681\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     29/29     3.78G   0.02675   0.01007   0.01323         8       640: 100% 22/22 [00:22<00:00,  1.00s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:02<00:00,  1.18s/it]\n",
            "                 all         60         60      0.945      0.853      0.951      0.626\n",
            "               chips         60         12          1      0.917      0.968      0.618\n",
            "           chocolate         60         12          1      0.725      0.894      0.596\n",
            "            icecream         60         12      0.951      0.917      0.984      0.417\n",
            "               maggi         60         12      0.855       0.75      0.919       0.76\n",
            "           softdrink         60         12       0.92      0.958      0.989      0.737\n",
            "\n",
            "30 epochs completed in 0.202 hours.\n",
            "Optimizer stripped from runs/train/exp2/weights/last.pt, 14.4MB\n",
            "Optimizer stripped from runs/train/exp2/weights/best.pt, 14.4MB\n",
            "Results saved to \u001b[1mruns/train/exp2\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXsLrIW_3oqc"
      },
      "source": [
        "**Copy weights from the YOLOv5 notebook saved at runs/train/exp2/weights/best.pt to Google Drive**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_9Ee0CF1DTT"
      },
      "source": [
        "# %cp /content/yolov5/runs/train/exp/weights/best.pt /content/gdrive/My\\ Drive"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_A9KbxIYObhs"
      },
      "source": [
        "# **Loading model weights**\n",
        "Once the weights are saved in Google Drive we may want to reload them in a later Google Colab Session hence we copy weights from Google Drive to a folder called \"weights\" in YOLOv5 directory\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuINKI2jI0XH"
      },
      "source": [
        "!mkdir /content/yolov5/weights"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDLmXiEDnMO2"
      },
      "source": [
        "%cp /content/gdrive/My\\ Drive/best.pt /content/yolov5/weights/best.pt"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAcYlqlc5-Ws"
      },
      "source": [
        "!mkdir /content/yolov5/Test_Data"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPS-tLUnEQF0"
      },
      "source": [
        "**Extracting necessary frames from video to perform object detection** \n",
        "\n",
        "The results are saved to runs/detect"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDK22ukVJdMF",
        "outputId": "5fe00891-10f7-43f1-866f-9323a32cd102"
      },
      "source": [
        "import cv2\n",
        "import os \n",
        "\n",
        "video = cv2.VideoCapture('/content/gdrive/MyDrive/test.mp4')\n",
        "fps = int(video.get(cv2.CAP_PROP_FPS))\n",
        "total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "print('Writing frames to files')\n",
        "for fno in range(0, total_frames, fps):\n",
        "    video.set(cv2.CAP_PROP_POS_FRAMES, fno)\n",
        "    ret, frame = video.read()\n",
        "    if ret:\n",
        "        name = '/content/yolov5/Test_Data/Frame(' + str(fno) + ').jpg'\n",
        "        cv2.imwrite(name, frame)\n",
        "\n",
        "s = !python detect.py --weights /content/yolov5/weights/best.pt --img 640 --conf 0.25 --source /content/yolov5/Test_Data/\n",
        "print(s)\n",
        "\n",
        "print('Clearing the file content')\n",
        "\n",
        "# Reading all the files in Test_data and deleting it\n",
        "for file_name in os.listdir('/content/yolov5/Test_Data'):\n",
        "    if file_name.endswith('.jpg'):\n",
        "        os.remove('/content/yolov5/Test_Data/' + file_name)        \n",
        "print('File content successfully cleared')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing frames to files\n",
            "['Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...', \"\\x1b[34m\\x1b[1mdetect: \\x1b[0mweights=['/content/yolov5/weights/best.pt'], source=/content/yolov5/Test_Data/, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False\", 'YOLOv5 ðŸš€ v5.0-483-g76d301b torch 1.9.0+cu102 CUDA:0 (Tesla K80, 11441.1875MB)', '', 'Fusing layers... ', 'Model Summary: 224 layers, 7064698 parameters, 0 gradients, 16.4 GFLOPs', 'image 1/3 /content/yolov5/Test_Data/Frame(0).jpg: 384x640 1 chocolate, 2 softdrinks, Done. (0.025s)', 'image 2/3 /content/yolov5/Test_Data/Frame(30).jpg: 384x640 2 chipss, 1 maggi, Done. (0.024s)', 'image 3/3 /content/yolov5/Test_Data/Frame(60).jpg: 384x640 1 chips, 1 icecream, Done. (0.024s)', 'Speed: 0.5ms pre-process, 24.3ms inference, 14.4ms NMS per image at shape (1, 3, 640, 640)', 'Results saved to \\x1b[1mruns/detect/exp\\x1b[0m']\n",
            "Clearing the file content\n",
            "File content successfully cleared\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XziT8cdSD5Xt"
      },
      "source": [
        "**Filtering out the outcomes in a dictionary**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HaqET2yTS3TH"
      },
      "source": [
        "# Creating initial filtered list for the outcome\n",
        "actual_list = []\n",
        "for i in range(len(s)):\n",
        "  if('Done' in s[i]):\n",
        "    actual_list.append(s[i])\n",
        "\n",
        "# Creating a dictionary for the outcome\n",
        "bill = {}\n",
        "classes = ['chocolate,','softdrinks,','chips,','icecream,', 'maggi,']\n",
        "for i in range(len(actual_list)):\n",
        "  sub_list = list(actual_list[i].split(' '))\n",
        "  for j in range(len(sub_list)):\n",
        "    if(sub_list[j] in classes):\n",
        "\n",
        "# Updating value for each class in the dictionary\n",
        "      if(sub_list[j] in list(bill.keys())):\n",
        "        bill[sub_list[j]] = bill[sub_list[j]] + int(sub_list[j-1])\n",
        "\n",
        "# Initialising the class values in the dictionary\n",
        "      else:\n",
        "        bill[sub_list[j]] = int(sub_list[j-1])\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLXEvM06Doyi"
      },
      "source": [
        "**Generating bill for all the grocery items detected**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_QizMRMTA7b",
        "outputId": "073fed43-7c09-422c-e92b-7ad492d36257"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# per unit cost for each item \n",
        "price = {'chocolate,' : 60 ,\n",
        "         'softdrinks,' : 45,\n",
        "         'chips,': 10,\n",
        "         'icecream,': 120,\n",
        "         'maggi,': 15}\n",
        "\n",
        "# Creating the bill in a Dataframe\n",
        "df = pd.DataFrame()\n",
        "df['item(s)']=bill.keys()\n",
        "df['quantity']=bill.values()\n",
        "price_l=[]\n",
        "\n",
        "# Calculating the price of each item\n",
        "for i in range(len(df)):\n",
        "  #print(df['item(s)'][i])\n",
        "  p=price[df['item(s)'][i]]\n",
        "  q=df['quantity'][i]\n",
        "  p=p*q\n",
        "  price_l.append(p)\n",
        "\n",
        "# Adding the price values to the dataframe \n",
        "df['price']=price_l\n",
        "\n",
        "# Displaying the output in a formatted way\n",
        "print(\"Bill Generated\"+'\\n',df)\n",
        "print(\"\\n\\n\"+\"Grand total: \",sum(df['price']))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bill Generated\n",
            "        item(s)  quantity  price\n",
            "0   chocolate,         1     60\n",
            "1  softdrinks,         2     90\n",
            "2       maggi,         1     15\n",
            "3       chips,         1     10\n",
            "4    icecream,         1    120\n",
            "\n",
            "\n",
            "Grand total:  295\n"
          ]
        }
      ]
    }
  ]
}